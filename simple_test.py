#!/usr/bin/env python3
"""
Simple test script to validate core functionality without external dependencies
"""

import sys
import os
import json
import numpy as np
import pandas as pd
from datetime import datetime

def test_basic_imports():
    """Test that we can import basic modules"""
    print("üß™ Testing basic imports...")
    
    try:
        import numpy as np
        import pandas as pd
        import json
        from datetime import datetime
        print("‚úÖ Basic imports successful")
        return True
    except ImportError as e:
        print(f"‚ùå Basic imports failed: {e}")
        return False

def test_data_generation():
    """Test synthetic data generation without ML dependencies"""
    print("üìä Testing data generation...")
    
    try:
        # Generate synthetic temperature and vibration data
        n_samples = 100
        
        # Temperature data (18-30¬∞C normal range)
        base_temp = 22.0
        temp_variation = np.random.normal(0, 3, n_samples)
        temperatures = base_temp + temp_variation
        
        # Add some anomalies (5% of data)
        anomaly_indices = np.random.choice(n_samples, size=int(0.05 * n_samples), replace=False)
        temperatures[anomaly_indices] = np.random.choice([5, 45], size=len(anomaly_indices))  # Extreme temps
        
        # Vibration data (0-5 normal range)
        base_vibration = 2.0
        vibration_variation = np.random.normal(0, 0.8, n_samples)
        vibrations = np.abs(base_vibration + vibration_variation)  # Ensure positive
        
        # Add vibration anomalies
        vibrations[anomaly_indices] = np.random.uniform(8, 12, size=len(anomaly_indices))  # High vibration
        
        # Create DataFrame
        data = pd.DataFrame({
            'timestamp': [datetime.now().isoformat() for _ in range(n_samples)],
            'device_id': [f'device_{i%5}' for i in range(n_samples)],
            'temperature': temperatures,
            'vibration': vibrations,
            'is_anomaly': [i in anomaly_indices for i in range(n_samples)]
        })
        
        print(f"‚úÖ Generated {len(data)} data points")
        print(f"Temperature range: {data['temperature'].min():.1f} - {data['temperature'].max():.1f}¬∞C")
        print(f"Vibration range: {data['vibration'].min():.2f} - {data['vibration'].max():.2f}")
        print(f"Anomaly rate: {data['is_anomaly'].mean():.1%}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Data generation failed: {e}")
        return False

def test_anomaly_detection_logic():
    """Test basic anomaly detection logic"""
    print("üîç Testing anomaly detection logic...")
    
    try:
        # Test cases
        test_cases = [
            {'temp': 25.0, 'vibration': 2.0, 'expected_anomaly': False, 'description': 'Normal values'},
            {'temp': 5.0, 'vibration': 2.0, 'expected_anomaly': True, 'description': 'Low temperature'},
            {'temp': 45.0, 'vibration': 2.0, 'expected_anomaly': True, 'description': 'High temperature'},
            {'temp': 25.0, 'vibration': 10.0, 'expected_anomaly': True, 'description': 'High vibration'},
            {'temp': 50.0, 'vibration': 12.0, 'expected_anomaly': True, 'description': 'Both anomalous'},
        ]
        
        # Define thresholds
        temp_min, temp_max = 10.0, 40.0
        vibration_max = 8.0
        
        passed_tests = 0
        
        for i, case in enumerate(test_cases):
            temp = case['temp']
            vibration = case['vibration']
            expected = case['expected_anomaly']
            
            # Apply detection logic
            temp_anomaly = temp < temp_min or temp > temp_max
            vibration_anomaly = vibration > vibration_max
            detected_anomaly = temp_anomaly or vibration_anomaly
            
            if detected_anomaly == expected:
                print(f"‚úÖ Test {i+1}: {case['description']} - PASSED")
                passed_tests += 1
            else:
                print(f"‚ùå Test {i+1}: {case['description']} - FAILED (expected: {expected}, got: {detected_anomaly})")
        
        print(f"Anomaly detection tests: {passed_tests}/{len(test_cases)} passed")
        return passed_tests == len(test_cases)
        
    except Exception as e:
        print(f"‚ùå Anomaly detection logic test failed: {e}")
        return False

def test_json_processing():
    """Test JSON message processing"""
    print("üìù Testing JSON message processing...")
    
    try:
        # Sample IoT message
        sample_message = {
            "device_id": "temp_sensor_001",
            "timestamp": datetime.now().isoformat(),
            "device_type": "temperature_sensor",
            "location": {
                "building": "A",
                "floor": 1,
                "room": "101"
            },
            "sensor_data": {
                "temperature": 25.5,
                "vibration": 2.1
            }
        }
        
        # Convert to JSON and back (simulating Pub/Sub message processing)
        json_str = json.dumps(sample_message)
        parsed_message = json.loads(json_str)
        
        # Validate structure
        required_fields = ['device_id', 'timestamp', 'device_type', 'sensor_data']
        for field in required_fields:
            if field not in parsed_message:
                raise ValueError(f"Missing required field: {field}")
        
        # Validate sensor data
        sensor_data = parsed_message['sensor_data']
        if 'temperature' not in sensor_data or 'vibration' not in sensor_data:
            raise ValueError("Missing temperature or vibration data")
        
        print(f"‚úÖ JSON processing successful")
        print(f"Device: {parsed_message['device_id']}")
        print(f"Temperature: {sensor_data['temperature']}¬∞C")
        print(f"Vibration: {sensor_data['vibration']}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå JSON processing failed: {e}")
        return False

def test_bigquery_schema_compatibility():
    """Test BigQuery schema compatibility"""
    print("üóÑÔ∏è Testing BigQuery schema compatibility...")
    
    try:
        # Expected BigQuery schema fields
        expected_fields = [
            'device_id', 'device_type', 'location', 'timestamp', 'processed_at',
            'temperature', 'vibration_level', 'is_anomaly', 'anomaly_type',
            'anomaly_score', 'anomaly_reasons', 'anomaly_severity',
            'temp_anomaly', 'vibration_anomaly', 'temp_z_score', 'vibration_z_score'
        ]
        
        # Create sample data matching schema
        sample_data = {
            'device_id': 'temp_sensor_001',
            'device_type': 'temperature_sensor',
            'location': '{"building": "A", "floor": 1}',
            'timestamp': datetime.now().isoformat(),
            'processed_at': datetime.now().isoformat(),
            'temperature': 25.5,
            'vibration_level': 2.1,
            'is_anomaly': False,
            'anomaly_type': 'normal',
            'anomaly_score': 0.0,
            'anomaly_reasons': '[]',
            'anomaly_severity': 'normal',
            'temp_anomaly': False,
            'vibration_anomaly': False,
            'temp_z_score': 0.7,
            'vibration_z_score': 0.1
        }
        
        # Validate all expected fields are present
        missing_fields = []
        for field in expected_fields:
            if field not in sample_data:
                missing_fields.append(field)
        
        if missing_fields:
            raise ValueError(f"Missing fields: {missing_fields}")
        
        # Validate data types
        type_checks = [
            ('device_id', str),
            ('temperature', (int, float)),
            ('vibration_level', (int, float)),
            ('is_anomaly', bool),
            ('temp_z_score', (int, float))
        ]
        
        for field, expected_type in type_checks:
            value = sample_data[field]
            if not isinstance(value, expected_type):
                raise TypeError(f"Field {field} has wrong type: {type(value)}")
        
        print(f"‚úÖ BigQuery schema compatibility verified")
        print(f"Schema has {len(expected_fields)} fields")
        
        return True
        
    except Exception as e:
        print(f"‚ùå BigQuery schema test failed: {e}")
        return False

def test_streamlit_data_format():
    """Test data format for Streamlit dashboard"""
    print("üìä Testing Streamlit data format...")
    
    try:
        # Create sample DataFrame that Streamlit would use
        n_points = 50
        
        data = {
            'timestamp': pd.date_range(start='2024-01-01', periods=n_points, freq='H'),
            'device_id': [f'device_{i%3}' for i in range(n_points)],
            'device_type': ['temperature_sensor'] * n_points,
            'temperature': np.random.normal(22, 3, n_points),
            'vibration': np.abs(np.random.normal(2, 0.5, n_points)),
            'is_anomaly': np.random.choice([True, False], n_points, p=[0.1, 0.9]),
            'temp_z_score': np.random.normal(0, 1, n_points),
            'vibration_z_score': np.random.normal(0, 1, n_points)
        }
        
        df = pd.DataFrame(data)
        
        # Test operations that Streamlit dashboard would perform
        total_readings = len(df)
        anomaly_count = df['is_anomaly'].sum()
        anomaly_rate = (anomaly_count / total_readings * 100) if total_readings > 0 else 0
        unique_devices = df['device_id'].nunique()
        avg_temp = df['temperature'].mean()
        
        # Test filtering
        normal_data = df[df['is_anomaly'] == False]
        anomaly_data = df[df['is_anomaly'] == True]
        
        # Test aggregation
        device_stats = df.groupby('device_id').agg({
            'temperature': ['mean', 'std'],
            'vibration': ['mean', 'std'],
            'is_anomaly': 'sum'
        })
        
        print(f"‚úÖ Streamlit data format test passed")
        print(f"Total readings: {total_readings}")
        print(f"Anomalies: {anomaly_count} ({anomaly_rate:.1f}%)")
        print(f"Unique devices: {unique_devices}")
        print(f"Average temperature: {avg_temp:.1f}¬∞C")
        print(f"Device stats shape: {device_stats.shape}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Streamlit data format test failed: {e}")
        return False

def main():
    """Run all simple tests"""
    print("üß™ Running Simple IoT Anomaly Detection System Tests")
    print("=" * 60)
    
    tests = [
        ("Basic Imports", test_basic_imports),
        ("Data Generation", test_data_generation),
        ("Anomaly Detection Logic", test_anomaly_detection_logic),
        ("JSON Processing", test_json_processing),
        ("BigQuery Schema", test_bigquery_schema_compatibility),
        ("Streamlit Data Format", test_streamlit_data_format)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        print(f"\n{'='*15} {test_name} {'='*15}")
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"‚ùå {test_name} test crashed: {e}")
            results[test_name] = False
    
    # Summary
    print("\n" + "="*60)
    print("üèÅ TEST SUMMARY")
    print("="*60)
    
    passed = 0
    total = len(tests)
    
    for test_name, result in results.items():
        status = "‚úÖ PASSED" if result else "‚ùå FAILED"
        print(f"{test_name:.<35} {status}")
        if result:
            passed += 1
    
    print(f"\nOverall: {passed}/{total} tests passed ({passed/total*100:.1f}%)")
    
    if passed == total:
        print("üéâ All core functionality tests passed!")
        print("üí° System is ready for deployment (install full dependencies for production)")
        return 0
    else:
        print("‚ö†Ô∏è Some tests failed. Please review and fix issues.")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)